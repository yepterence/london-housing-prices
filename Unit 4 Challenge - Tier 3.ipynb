{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 City of London Barking & Dagenham     Barnet     Bexley  \\\n",
       "0        NaT      E09000001          E09000002  E09000003  E09000004   \n",
       "1 1995-01-01          91449            50460.2    93284.5    64958.1   \n",
       "2 1995-02-01        82202.8            51085.8    93190.2    64787.9   \n",
       "3 1995-03-01        79120.7              51269    92247.5    64367.5   \n",
       "4 1995-04-01        77101.2            53133.5    90762.9    64277.7   \n",
       "\n",
       "       Brent    Bromley     Camden    Croydon     Ealing  ... NORTH WEST  \\\n",
       "0  E09000005  E09000006  E09000007  E09000008  E09000009  ...  E12000002   \n",
       "1    71306.6    81671.5     120933    69158.2    79885.9  ...    43958.5   \n",
       "2    72022.3    81657.6     119509    68951.1    80897.1  ...    43925.4   \n",
       "3    72015.8    81449.3     120282    68712.4    81379.9  ...    44434.9   \n",
       "4    72965.6    81124.4     120098      68610    82188.9  ...    44267.8   \n",
       "\n",
       "  YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND     LONDON  \\\n",
       "0          E12000003     E12000004     E12000005       E12000006  E12000007   \n",
       "1            44803.4       45544.5       48527.5         56701.6    74435.8   \n",
       "2            44528.8       46051.6       49341.3         56593.6    72777.9   \n",
       "3            45200.5       45383.8       49442.2         56171.2    73896.8   \n",
       "4            45614.3       46124.2       49455.9         56567.9    74455.3   \n",
       "\n",
       "  SOUTH EAST SOUTH WEST Unnamed: 47    England  \n",
       "0  E12000008  E12000009         NaN  E92000001  \n",
       "1    64018.9    54705.2         NaN    53202.8  \n",
       "2      63715    54356.1         NaN    53096.2  \n",
       "3    64113.6    53583.1         NaN    53201.3  \n",
       "4    64623.2      54786         NaN    53590.9  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', parse_dates=True, index_col= None)\n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 310 entries, 0 to 309\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            309 non-null    datetime64[ns]\n",
      " 1   City of London        310 non-null    object        \n",
      " 2   Barking & Dagenham    310 non-null    object        \n",
      " 3   Barnet                310 non-null    object        \n",
      " 4   Bexley                310 non-null    object        \n",
      " 5   Brent                 310 non-null    object        \n",
      " 6   Bromley               310 non-null    object        \n",
      " 7   Camden                310 non-null    object        \n",
      " 8   Croydon               310 non-null    object        \n",
      " 9   Ealing                310 non-null    object        \n",
      " 10  Enfield               310 non-null    object        \n",
      " 11  Greenwich             310 non-null    object        \n",
      " 12  Hackney               310 non-null    object        \n",
      " 13  Hammersmith & Fulham  310 non-null    object        \n",
      " 14  Haringey              310 non-null    object        \n",
      " 15  Harrow                310 non-null    object        \n",
      " 16  Havering              310 non-null    object        \n",
      " 17  Hillingdon            310 non-null    object        \n",
      " 18  Hounslow              310 non-null    object        \n",
      " 19  Islington             310 non-null    object        \n",
      " 20  Kensington & Chelsea  310 non-null    object        \n",
      " 21  Kingston upon Thames  310 non-null    object        \n",
      " 22  Lambeth               310 non-null    object        \n",
      " 23  Lewisham              310 non-null    object        \n",
      " 24  Merton                310 non-null    object        \n",
      " 25  Newham                310 non-null    object        \n",
      " 26  Redbridge             310 non-null    object        \n",
      " 27  Richmond upon Thames  310 non-null    object        \n",
      " 28  Southwark             310 non-null    object        \n",
      " 29  Sutton                310 non-null    object        \n",
      " 30  Tower Hamlets         310 non-null    object        \n",
      " 31  Waltham Forest        310 non-null    object        \n",
      " 32  Wandsworth            310 non-null    object        \n",
      " 33  Westminster           310 non-null    object        \n",
      " 34  Unnamed: 34           0 non-null      float64       \n",
      " 35  Inner London          310 non-null    object        \n",
      " 36  Outer London          310 non-null    object        \n",
      " 37  Unnamed: 37           0 non-null      float64       \n",
      " 38  NORTH EAST            310 non-null    object        \n",
      " 39  NORTH WEST            310 non-null    object        \n",
      " 40  YORKS & THE HUMBER    310 non-null    object        \n",
      " 41  EAST MIDLANDS         310 non-null    object        \n",
      " 42  WEST MIDLANDS         310 non-null    object        \n",
      " 43  EAST OF ENGLAND       310 non-null    object        \n",
      " 44  LONDON                310 non-null    object        \n",
      " 45  SOUTH EAST            310 non-null    object        \n",
      " 46  SOUTH WEST            310 non-null    object        \n",
      " 47  Unnamed: 47           0 non-null      float64       \n",
      " 48  England               310 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(45)\n",
      "memory usage: 118.8+ KB\n"
     ]
    }
   ],
   "source": [
    "properties.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial insights:\n",
    "1. There are null columns placed in the sheet to segregate the various buroughs within London, Inner&Outer London, the regions of England in comparison with London and finally England as a whole.\n",
    "2. The subsequent row after the column names contains unique IDs of each region. \n",
    "\n",
    "This information will drive how we clean this dataset. \n",
    "1. Keeping the unique IDs will allow us to keep the information accurate, it is best we segregate the region IDs and column names into a different dataframe or dictionary.\n",
    "2. Segregate the regions into separate dataframes. As each of these will allow us to compare the data and provide context to our analysis.\n",
    "3. Set the index column as date. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>1995-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "      <td>2020-05-01 00:00:00</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>2020-08-01 00:00:00</td>\n",
       "      <td>2020-09-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>104473</td>\n",
       "      <td>...</td>\n",
       "      <td>737275</td>\n",
       "      <td>774386</td>\n",
       "      <td>797666</td>\n",
       "      <td>833060</td>\n",
       "      <td>904136</td>\n",
       "      <td>905739</td>\n",
       "      <td>871203</td>\n",
       "      <td>786020</td>\n",
       "      <td>796283</td>\n",
       "      <td>793046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>51471.6</td>\n",
       "      <td>...</td>\n",
       "      <td>301283</td>\n",
       "      <td>303109</td>\n",
       "      <td>302613</td>\n",
       "      <td>301367</td>\n",
       "      <td>293307</td>\n",
       "      <td>293309</td>\n",
       "      <td>300013</td>\n",
       "      <td>304737</td>\n",
       "      <td>305534</td>\n",
       "      <td>303389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>93273.1</td>\n",
       "      <td>...</td>\n",
       "      <td>519306</td>\n",
       "      <td>521263</td>\n",
       "      <td>515963</td>\n",
       "      <td>522788</td>\n",
       "      <td>528982</td>\n",
       "      <td>527537</td>\n",
       "      <td>517901</td>\n",
       "      <td>520120</td>\n",
       "      <td>523380</td>\n",
       "      <td>535340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>64509.5</td>\n",
       "      <td>...</td>\n",
       "      <td>336302</td>\n",
       "      <td>335659</td>\n",
       "      <td>338038</td>\n",
       "      <td>338945</td>\n",
       "      <td>342117</td>\n",
       "      <td>339125</td>\n",
       "      <td>340975</td>\n",
       "      <td>344540</td>\n",
       "      <td>348110</td>\n",
       "      <td>343470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                    1                    2    \\\n",
       "Unnamed: 0                NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "City of London      E09000001                91449              82202.8   \n",
       "Barking & Dagenham  E09000002              50460.2              51085.8   \n",
       "Barnet              E09000003              93284.5              93190.2   \n",
       "Bexley              E09000004              64958.1              64787.9   \n",
       "\n",
       "                                    3                    4    \\\n",
       "Unnamed: 0          1995-03-01 00:00:00  1995-04-01 00:00:00   \n",
       "City of London                  79120.7              77101.2   \n",
       "Barking & Dagenham                51269              53133.5   \n",
       "Barnet                          92247.5              90762.9   \n",
       "Bexley                          64367.5              64277.7   \n",
       "\n",
       "                                    5                    6    \\\n",
       "Unnamed: 0          1995-05-01 00:00:00  1995-06-01 00:00:00   \n",
       "City of London                  84409.1              94900.5   \n",
       "Barking & Dagenham              53042.2              53700.3   \n",
       "Barnet                            90258              90107.2   \n",
       "Bexley                          63997.1              64252.3   \n",
       "\n",
       "                                    7                    8    \\\n",
       "Unnamed: 0          1995-07-01 00:00:00  1995-08-01 00:00:00   \n",
       "City of London                   110128               112329   \n",
       "Barking & Dagenham              52113.1              52232.2   \n",
       "Barnet                          91441.2              92361.3   \n",
       "Bexley                          63722.7              64432.6   \n",
       "\n",
       "                                    9    ...                  300  \\\n",
       "Unnamed: 0          1995-09-01 00:00:00  ...  2019-12-01 00:00:00   \n",
       "City of London                   104473  ...               737275   \n",
       "Barking & Dagenham              51471.6  ...               301283   \n",
       "Barnet                          93273.1  ...               519306   \n",
       "Bexley                          64509.5  ...               336302   \n",
       "\n",
       "                                    301                  302  \\\n",
       "Unnamed: 0          2020-01-01 00:00:00  2020-02-01 00:00:00   \n",
       "City of London                   774386               797666   \n",
       "Barking & Dagenham               303109               302613   \n",
       "Barnet                           521263               515963   \n",
       "Bexley                           335659               338038   \n",
       "\n",
       "                                    303                  304  \\\n",
       "Unnamed: 0          2020-03-01 00:00:00  2020-04-01 00:00:00   \n",
       "City of London                   833060               904136   \n",
       "Barking & Dagenham               301367               293307   \n",
       "Barnet                           522788               528982   \n",
       "Bexley                           338945               342117   \n",
       "\n",
       "                                    305                  306  \\\n",
       "Unnamed: 0          2020-05-01 00:00:00  2020-06-01 00:00:00   \n",
       "City of London                   905739               871203   \n",
       "Barking & Dagenham               293309               300013   \n",
       "Barnet                           527537               517901   \n",
       "Bexley                           339125               340975   \n",
       "\n",
       "                                    307                  308  \\\n",
       "Unnamed: 0          2020-07-01 00:00:00  2020-08-01 00:00:00   \n",
       "City of London                   786020               796283   \n",
       "Barking & Dagenham               304737               305534   \n",
       "Barnet                           520120               523380   \n",
       "Bexley                           344540               348110   \n",
       "\n",
       "                                    309  \n",
       "Unnamed: 0          2020-09-01 00:00:00  \n",
       "City of London                   793046  \n",
       "Barking & Dagenham               303389  \n",
       "Barnet                           535340  \n",
       "Bexley                           343470  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.columns\n",
    "properties_T = properties.T\n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=49, step=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properties_T.index\n",
    "# Resetting index \n",
    "properties_T = properties_T.reset_index()\n",
    "# print out index\n",
    "properties_T.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dates as column headings\n",
    "properties_T.columns = properties_T.iloc[0]\n",
    "# Dropping redundant columns\n",
    "properties_T = properties_T.drop(0)\n",
    "properties_T = properties_T.rename(columns = {'Unnamed: 0':'London_Boroughs', pd.NaT:'regionID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Boroughs    14832\n",
       "regionID           13905\n",
       "Date               14832\n",
       "Average_price      13905\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing properties_T \n",
    "cleaned_properties = pd.melt(properties_T, id_vars= ['London_Boroughs', 'regionID'])\n",
    "# modifying column names to meaningful names\n",
    "cleaned_properties = cleaned_properties.rename(columns = {0: 'Date', 'value': 'Average_price'})\n",
    "# check results\n",
    "cleaned_properties.head()\n",
    "cleaned_properties.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Boroughs            object\n",
       "regionID                   object\n",
       "Date               datetime64[ns]\n",
       "Average_price             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coercing average_price column to float\n",
    "cleaned_properties['Average_price'] = pd.to_numeric(cleaned_properties['Average_price'])\n",
    "cleaned_properties.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13905 entries, 0 to 14831\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   London_Boroughs  13905 non-null  object        \n",
      " 1   regionID         13905 non-null  object        \n",
      " 2   Date             13905 non-null  datetime64[ns]\n",
      " 3   Average_price    13905 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 543.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# cleaned_properties.info()\n",
    "# checking Unnamed column\n",
    "cleaned_properties[cleaned_properties['London_Boroughs'] == 'Unnamed: 34'].head()\n",
    "# Looking at this column, we can see that the entire column has only nan entries, and if we look at the original dataset\n",
    "# this column was left purposely blank as a way to segregate the data\n",
    "# after dropping the values\n",
    "cleaned_properties = cleaned_properties.dropna()\n",
    "# we can see that the number of entries dropped from 14832 to 13905 \n",
    "cleaned_properties.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Boroughs</th>\n",
       "      <th>regionID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.22660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.51832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.09036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.56698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>81671.47692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Camden</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>120932.88810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>69158.16225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>79885.89069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72514.69096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>E09000011</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>62300.10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hackney</td>\n",
       "      <td>E09000012</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>61296.52637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hammersmith &amp; Fulham</td>\n",
       "      <td>E09000013</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>124902.86020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Haringey</td>\n",
       "      <td>E09000014</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>76287.56947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Harrow</td>\n",
       "      <td>E09000015</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>84769.52599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Havering</td>\n",
       "      <td>E09000016</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>68000.13774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>73834.82964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hounslow</td>\n",
       "      <td>E09000018</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72231.70537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Islington</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>92516.48557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kensington &amp; Chelsea</td>\n",
       "      <td>E09000020</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>182694.83260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kingston upon Thames</td>\n",
       "      <td>E09000021</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>80875.84843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>67770.98843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lewisham</td>\n",
       "      <td>E09000023</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>60491.26109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Merton</td>\n",
       "      <td>E09000024</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>82070.61330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Newham</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>53539.31919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Redbridge</td>\n",
       "      <td>E09000026</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72189.58437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Richmond upon Thames</td>\n",
       "      <td>E09000027</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>109326.12450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Southwark</td>\n",
       "      <td>E09000028</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>67885.20344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sutton</td>\n",
       "      <td>E09000029</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71536.97357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>E09000030</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>59865.18995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>E09000031</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>61319.44913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>88559.04381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>E09000033</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>133025.27720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>51085.77983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>93190.16963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>64787.92069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>72022.26197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>81657.55944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Camden</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>119508.86220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>68951.09542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>80897.06551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>73155.19746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         London_Boroughs   regionID       Date  Average_price\n",
       "0         City of London  E09000001 1995-01-01    91448.98487\n",
       "1     Barking & Dagenham  E09000002 1995-01-01    50460.22660\n",
       "2                 Barnet  E09000003 1995-01-01    93284.51832\n",
       "3                 Bexley  E09000004 1995-01-01    64958.09036\n",
       "4                  Brent  E09000005 1995-01-01    71306.56698\n",
       "5                Bromley  E09000006 1995-01-01    81671.47692\n",
       "6                 Camden  E09000007 1995-01-01   120932.88810\n",
       "7                Croydon  E09000008 1995-01-01    69158.16225\n",
       "8                 Ealing  E09000009 1995-01-01    79885.89069\n",
       "9                Enfield  E09000010 1995-01-01    72514.69096\n",
       "10             Greenwich  E09000011 1995-01-01    62300.10169\n",
       "11               Hackney  E09000012 1995-01-01    61296.52637\n",
       "12  Hammersmith & Fulham  E09000013 1995-01-01   124902.86020\n",
       "13              Haringey  E09000014 1995-01-01    76287.56947\n",
       "14                Harrow  E09000015 1995-01-01    84769.52599\n",
       "15              Havering  E09000016 1995-01-01    68000.13774\n",
       "16            Hillingdon  E09000017 1995-01-01    73834.82964\n",
       "17              Hounslow  E09000018 1995-01-01    72231.70537\n",
       "18             Islington  E09000019 1995-01-01    92516.48557\n",
       "19  Kensington & Chelsea  E09000020 1995-01-01   182694.83260\n",
       "20  Kingston upon Thames  E09000021 1995-01-01    80875.84843\n",
       "21               Lambeth  E09000022 1995-01-01    67770.98843\n",
       "22              Lewisham  E09000023 1995-01-01    60491.26109\n",
       "23                Merton  E09000024 1995-01-01    82070.61330\n",
       "24                Newham  E09000025 1995-01-01    53539.31919\n",
       "25             Redbridge  E09000026 1995-01-01    72189.58437\n",
       "26  Richmond upon Thames  E09000027 1995-01-01   109326.12450\n",
       "27             Southwark  E09000028 1995-01-01    67885.20344\n",
       "28                Sutton  E09000029 1995-01-01    71536.97357\n",
       "29         Tower Hamlets  E09000030 1995-01-01    59865.18995\n",
       "30        Waltham Forest  E09000031 1995-01-01    61319.44913\n",
       "31            Wandsworth  E09000032 1995-01-01    88559.04381\n",
       "32           Westminster  E09000033 1995-01-01   133025.27720\n",
       "48        City of London  E09000001 1995-02-01    82202.77314\n",
       "49    Barking & Dagenham  E09000002 1995-02-01    51085.77983\n",
       "50                Barnet  E09000003 1995-02-01    93190.16963\n",
       "51                Bexley  E09000004 1995-02-01    64787.92069\n",
       "52                 Brent  E09000005 1995-02-01    72022.26197\n",
       "53               Bromley  E09000006 1995-02-01    81657.55944\n",
       "54                Camden  E09000007 1995-02-01   119508.86220\n",
       "55               Croydon  E09000008 1995-02-01    68951.09542\n",
       "56                Ealing  E09000009 1995-02-01    80897.06551\n",
       "57               Enfield  E09000010 1995-02-01    73155.19746"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaned_properties['London_Boroughs'].unique()\n",
    "# cleaned_properties.shape\n",
    "\n",
    "# If we look up the homepage of dataset, we see that there are 32 boroughs in London including the city of London.\n",
    "# Due to our current scope of studying the boroughs of London, we can exclude the other columns such as England as a whole.\n",
    "# There are only  32 boroughs in London but there are still 13905 entries\n",
    "exclude_regions = ['Inner London', 'Outer London', \n",
    "               'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', \n",
    "               'EAST MIDLANDS', 'WEST MIDLANDS',\n",
    "              'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST', \n",
    "              'SOUTH WEST', 'England']\n",
    "# After creating the exclusion list, we'll filter for only regions within London\n",
    "df = cleaned_properties[~cleaned_properties.London_Boroughs.isin(exclude_regions)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
